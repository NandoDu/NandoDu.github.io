<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>网络爬虫入门 | NandoDu</title><meta name="description" content="这是一篇爬虫入门的技术笔记。"><meta name="keywords" content="爬虫,后端"><meta name="author" content="NandoDu"><meta name="copyright" content="NandoDu"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/%E5%A4%B4%E5%83%8F.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="网络爬虫入门"><meta name="twitter:description" content="这是一篇爬虫入门的技术笔记。"><meta name="twitter:image" content="https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/u%3D570608382%2C3161007299%26fm%3D26%26gp%3D0.jpg"><meta property="og:type" content="article"><meta property="og:title" content="网络爬虫入门"><meta property="og:url" content="nandodu.cn/2020/04/29/crawler/"><meta property="og:site_name" content="NandoDu"><meta property="og:description" content="这是一篇爬虫入门的技术笔记。"><meta property="og:image" content="https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/u%3D570608382%2C3161007299%26fm%3D26%26gp%3D0.jpg"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="nandodu.cn/2020/04/29/crawler/"><link rel="prev" title="常用C++输入场景" href="/nandodu.cn/2020/05/12/C++io/"><link rel="next" title="从零开发微信小程序（四）" href="/nandodu.cn/2020/04/26/wechat4/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"do,re,mi,fa,so,la,xi","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"Press","message_next":"to bookmark this page"},"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/%E5%A4%B4%E5%83%8F.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">12</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">14</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#环境准备"><span class="toc-number">1.</span> <span class="toc-text">环境准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requests库的安装"><span class="toc-number">2.</span> <span class="toc-text">Requests库的安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requests库的get-方法"><span class="toc-number">3.</span> <span class="toc-text">Requests库的get()方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#爬取网页的通用代码框架"><span class="toc-number">4.</span> <span class="toc-text">爬取网页的通用代码框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requests库的主要方法"><span class="toc-number">5.</span> <span class="toc-text">Requests库的主要方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requests库主要方法解析"><span class="toc-number">6.</span> <span class="toc-text">Requests库主要方法解析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#网络爬虫引发的问题"><span class="toc-number">7.</span> <span class="toc-text">网络爬虫引发的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#网络爬虫的尺寸"><span class="toc-number">7.1.</span> <span class="toc-text">网络爬虫的尺寸</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#网络爬虫引发的问题-1"><span class="toc-number">7.2.</span> <span class="toc-text">网络爬虫引发的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#网络爬虫的限制"><span class="toc-number">7.3.</span> <span class="toc-text">网络爬虫的限制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#来源审查：判断User-Agent进行限制"><span class="toc-number">7.3.1.</span> <span class="toc-text">来源审查：判断User-Agent进行限制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#发布公告：Robots协议"><span class="toc-number">7.3.2.</span> <span class="toc-text">发布公告：Robots协议</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Robots协议"><span class="toc-number">8.</span> <span class="toc-text">Robots协议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Robots协议的使用"><span class="toc-number">9.</span> <span class="toc-text">Robots协议的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#访问亚马逊商品页面实例"><span class="toc-number">10.</span> <span class="toc-text">访问亚马逊商品页面实例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#百度搜索关键词提交实例"><span class="toc-number">11.</span> <span class="toc-text">百度搜索关键词提交实例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Beautiful-Soup库的安装"><span class="toc-number">12.</span> <span class="toc-text">Beautiful Soup库的安装</span></a></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="color"></div><div class="post-bg" id="nav" style="background-image: url(https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/u%3D570608382%2C3161007299%26fm%3D26%26gp%3D0.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">NandoDu</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">网络爬虫入门</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="Created 2020-04-29 17:37:06"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2020-04-29</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="Updated 2020-04-29 22:44:41"><i class="fa fa-history" aria-hidden="true"></i> Updated 2020-04-29</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><p>学习爬虫的契机是小程序后端开发拟用这样的技术，我在这里简单整理一些爬虫的使用方法，方便以后使用的时候查阅。</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul>
<li>python环境配置</li>
<li>pycharm IDE</li>
<li>requests库的安装</li>
</ul>
<h2 id="Requests库的安装"><a href="#Requests库的安装" class="headerlink" title="Requests库的安装"></a>Requests库的安装</h2><p>&emsp;&emsp;以管理员的身份运行命令行，输入命令：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;然后进入IDE通过简单的代码验证requests是否安装成功（这里我们打开的是IDE中的python console进行模拟运行）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.status_code</span><br><span class="line"><span class="number">200</span>  // 出现<span class="number">200</span>代表连接成功</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.encoding = <span class="string">'utf-8'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.text</span><br><span class="line">(此处应显示百度的网页内容)</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;经过这样简单的验证，我们的requests库就安装成功了。</p>
<blockquote>
<p>当我们使用pycharm作为网络爬虫的IDE时，有时我们把r.encoding设置成utf-8后，依然出现乱码，这个时候我们要打开pycharm的File-&gt;Settings-&gt;Editor-&gt;File Encodings，更改Global Encoding和Project Encoding为utf-8，并在Path中添加当前py文件，设置编码为utf-8，修改Default encoding for properties files为utf-8，此时便可以解决我们的乱码问题。</p>
</blockquote>
<h2 id="Requests库的get-方法"><a href="#Requests库的get-方法" class="headerlink" title="Requests库的get()方法"></a>Requests库的get()方法</h2><p>&emsp;&emsp;下面我们来分析前面一段给出的代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = requests.get(url)</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;此处的requests.get(url)相当于我们创建了一个Requests对象，r相当于创建了一个Response对象，get方法用来对应HTML的get。</p>
<p>&emsp;&emsp;Response对象有如下常用属性：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">r.status_code:       HTTP请求的返回状态，200表示连接成功，404表示失败</span><br><span class="line">r.text:              HTTP相应内容的字符串形式，即url对应的页面内容</span><br><span class="line">r.encoding:          从HTTP header中猜测的响应内容编码方式</span><br><span class="line">r.apparent_encoding: 从内容中分析出的响应内容编码方式（备选编码方式）</span><br><span class="line">r.content:           HTTP响应内容的二进制形式</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;注意，如果header中不存在charset，则认为编码为ISO-8859-1，所以我们常常需要更改r.encoding，来使我们得到的内容中的汉字得到正确的编码。</p>
<h2 id="爬取网页的通用代码框架"><a href="#爬取网页的通用代码框架" class="headerlink" title="爬取网页的通用代码框架"></a>爬取网页的通用代码框架</h2><p>&emsp;&emsp;首先，我们要理解Requests库的异常：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">requests.ConnectionError:  网络连接错误异常，如DNS查询失败、拒绝连接等</span><br><span class="line">requests.HTTPError:        HTTP错误异常</span><br><span class="line">requests.URLRequired:      URL缺失异常</span><br><span class="line">requests.TooManyRedirects: 超过最大重定向次数，产生重定向异常</span><br><span class="line">requests.ConnectTimeout:   连接远程服务器超时异常</span><br><span class="line">requests.Timeout:          请求URL超时，产生超时异常</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;接着，我们要理解Response库的异常：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">r.raise_for_status(): 如果不是200，产生异常requests.HTTPError</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;下面我们给出爬取网页的通用代码框架：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout = <span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    url = <span class="string">"http://www.baidu.com"</span></span><br><span class="line">    print(getHTMLText(url))</span><br></pre></td></tr></table></figure>

<h2 id="Requests库的主要方法"><a href="#Requests库的主要方法" class="headerlink" title="Requests库的主要方法"></a>Requests库的主要方法</h2><p>&emsp;&emsp;Requests库有7个主要方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">requests.request(): 构造一个请求，支撑以下各方法的基础方法</span><br><span class="line">requests.get():     获取HTML网页的主要方法，对应于HTTP的GET</span><br><span class="line">requests.head():    获取HTML网页头信息的方法，对应于HTTP的HEAD</span><br><span class="line">requests.post():    向HTML网页提交POST请求的方法，对应于HTTP的POST</span><br><span class="line">requests.put():     向HTML网页提交PUT请求的方法，对应于HTTP的PUT</span><br><span class="line">requests.patch():   向HTML网页提交局部修改请求，对应于HTTP的PATCH</span><br><span class="line">requests.delete():  向HTML页面提交删除请求，对应于HTTP的DELETE</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;对应的HTTP协议对资源有6种操作：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET:    请求获取URL位置的资源</span><br><span class="line">HEAD:   请求获取URL位置资源的响应消息报告，即获得该资源的头部信息</span><br><span class="line">POST:   请求向URL位置的资源后附加新的数据</span><br><span class="line">PUT:    请求向URL位置存储一个资源，覆盖原URL位置的资源</span><br><span class="line">PATCH:  请求局部更新URL位置的资源，即改变该处资源的部分内容</span><br><span class="line">DELETE: 请求删除URL位置存储的资源</span><br></pre></td></tr></table></figure>

<h2 id="Requests库主要方法解析"><a href="#Requests库主要方法解析" class="headerlink" title="Requests库主要方法解析"></a>Requests库主要方法解析</h2><p>&emsp;&emsp;<strong>requests.request(method, url, **kwargs)</strong></p>
<p>&emsp;&emsp;**kwargs: 控制访问的参数，均为可选项</p>
<p>&emsp;&emsp;  params: 字典或字节序列，作为参数增加到url中</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>, <span class="string">'key2'</span>: <span class="string">'value2'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'GET'</span>, <span class="string">'http://python123.io/ws'</span>, params=kv)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(r.url)</span><br><span class="line">http://python123.io/ws?key1=value1&amp;key2=value2</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;data: 字典、字节序列或文件对象，作为Request的内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>, <span class="string">'key2'</span>: <span class="string">'value2'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>, <span class="string">'http://python123.io/ws'</span>, data=kv)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>body = <span class="string">'主体内容'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>, <span class="string">'http://python123.io/ws'</span>, data=body)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>此时，kv的内容不会加到url里，而是会加到url对应链接的内容中。</p>
</blockquote>
<p>&emsp;&emsp;json: JSON格式的数据，作为Request的内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>, <span class="string">'http://python123.io/ws'</span>, json=kv)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>此时，kv的内容会加到url对应的json文件中</p>
</blockquote>
<p>&emsp;&emsp;headers: 字典，HTTP定制头</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hd = &#123;<span class="string">'user-agent'</span>: <span class="string">'Chrome/10'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>, <span class="string">'http://python123.io/ws'</span>, headers=hd)</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;cookies: 字典或CookieJar，Request中的cookie</p>
<p>&emsp;&emsp;auth: 元组，支持HTTP认证功能</p>
<p>&emsp;&emsp;files: 字典类型，传输文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fs = &#123;<span class="string">'file'</span>: open(<span class="string">'data.xls'</span>, <span class="string">'rb'</span>)&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>, <span class="string">'http://python123.io/ws'</span>, files=fs)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>用于向url对应的链接提供文件</p>
</blockquote>
<p>&emsp;&emsp;timeout: 设定超时时间，秒为单位</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'GET'</span>, <span class="string">'http://www.baidu.com'</span>, timeout=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;proxies: 字典认证，设定访问代理服务器，可以增加登录认证</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pxs = &#123;<span class="string">'http'</span>: <span class="string">'http://user:pass@10.10.1:1234'</span></span><br><span class="line">           <span class="string">'https'</span>: <span class="string">'https://10.10.10.1:4321'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'GET'</span>, <span class="string">'http://www.baidu.com'</span>, proxies=pxs)</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;allow_redirects: True/False，默认为True，重定向开关</p>
<p>&emsp;&emsp;stream: True/False，默认为True，获取内容立即下载开关</p>
<p>&emsp;&emsp;verify: True/False，默认为True，认证SSL证书开关</p>
<p>&emsp;&emsp;cert: 本地SSL证书路径</p>
<h2 id="网络爬虫引发的问题"><a href="#网络爬虫引发的问题" class="headerlink" title="网络爬虫引发的问题"></a>网络爬虫引发的问题</h2><h3 id="网络爬虫的尺寸"><a href="#网络爬虫的尺寸" class="headerlink" title="网络爬虫的尺寸"></a>网络爬虫的尺寸</h3><ul>
<li><p>爬取网页，玩转网页：小规模，数据量小，爬取速度不敏感（Requests库）</p>
</li>
<li><p>爬取网站，爬取系列网站：中规模，数据规模较大，爬取速度敏感（Scrapy库）</p>
</li>
<li><p>爬取全网： 大规模，搜索引擎，爬取速度关键（定制开发）</p>
</li>
</ul>
<h3 id="网络爬虫引发的问题-1"><a href="#网络爬虫引发的问题-1" class="headerlink" title="网络爬虫引发的问题"></a>网络爬虫引发的问题</h3><ul>
<li><p>骚扰问题</p>
</li>
<li><p>法律风险</p>
</li>
<li><p>隐私泄露</p>
</li>
</ul>
<h3 id="网络爬虫的限制"><a href="#网络爬虫的限制" class="headerlink" title="网络爬虫的限制"></a>网络爬虫的限制</h3><h4 id="来源审查：判断User-Agent进行限制"><a href="#来源审查：判断User-Agent进行限制" class="headerlink" title="来源审查：判断User-Agent进行限制"></a>来源审查：判断User-Agent进行限制</h4><ul>
<li>检查来访HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问</li>
</ul>
<h4 id="发布公告：Robots协议"><a href="#发布公告：Robots协议" class="headerlink" title="发布公告：Robots协议"></a>发布公告：Robots协议</h4><ul>
<li>告知所有爬虫网站的爬取策略，要求爬虫遵守</li>
</ul>
<h2 id="Robots协议"><a href="#Robots协议" class="headerlink" title="Robots协议"></a>Robots协议</h2><ul>
<li><p>作用：网站告知网络爬虫哪些页面可以爬取，哪些不行</p>
</li>
<li><p>形式：在网站根目录下的robots.txt文件</p>
</li>
</ul>
<h2 id="Robots协议的使用"><a href="#Robots协议的使用" class="headerlink" title="Robots协议的使用"></a>Robots协议的使用</h2><ul>
<li><p>网络爬虫：自动或人工识别robots.txt，再进行内容爬取</p>
</li>
<li><p>约束性：Robots协议是建议但非约束性，网络爬虫可以不遵守，但存在法律风险</p>
</li>
<li><p><strong>类人行为可不参考Robots协议</strong></p>
</li>
</ul>
<h2 id="访问亚马逊商品页面实例"><a href="#访问亚马逊商品页面实例" class="headerlink" title="访问亚马逊商品页面实例"></a>访问亚马逊商品页面实例</h2><p>&emsp;&emsp;我们在按照前述模板访问亚马逊页面时，会出现503的访问错误，其中一个可能的原因，就是我们用于访问的headers不被亚马逊接受。此时，我们通过前面介绍的headers参数修改，可达到爬取商品信息的目的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.amazon.cn/dp/B07TTR34CQ?ref_=Oct_DLandingS_D_5d921679_60&amp;smid=A26HDXW89ZT98L"</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    kv = &#123;<span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0'</span>&#125;  // 模拟浏览器访问</span><br><span class="line">    r = requests.get(url, headers = kv)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    print(r.text[<span class="number">1000</span>:<span class="number">2000</span>])</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>

<h2 id="百度搜索关键词提交实例"><a href="#百度搜索关键词提交实例" class="headerlink" title="百度搜索关键词提交实例"></a>百度搜索关键词提交实例</h2><p>&emsp;&emsp;百度关键词搜索有着固定的地址格式，即”<a href="http://www.baidu.com/s?wd=keyword&quot;，我们可以通过Requests库来实现关键词的提交：" target="_blank" rel="noopener">http://www.baidu.com/s?wd=keyword&quot;，我们可以通过Requests库来实现关键词的提交：</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">keyword = <span class="string">"Python"</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    kv = &#123;<span class="string">'wd'</span>: keyword&#125;</span><br><span class="line">    r = requests.get(<span class="string">"http://www.baidu.com/s"</span>, params=kv)</span><br><span class="line">    print(r.request.url)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    print(len(r.text))</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Beautiful-Soup库的安装"><a href="#Beautiful-Soup库的安装" class="headerlink" title="Beautiful Soup库的安装"></a>Beautiful Soup库的安装</h2><p>&emsp;&emsp;以管理员的身份运行命令行，输入命令：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;然后我们验证BeautifulSoup库安装成功：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.status_code</span><br><span class="line"><span class="number">200</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.encoding = r.apparent_encoding</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.text</span><br><span class="line">(百度页面内容)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo, <span class="string">"html.parser"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(soup)</span><br><span class="line">(解析后内容)</span><br></pre></td></tr></table></figure>




</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">NandoDu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="/nandodu.cn/2020/04/29/crawler/">nandodu.cn/2020/04/29/crawler/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a><a class="post-meta__tags" href="/tags/%E5%90%8E%E7%AB%AF/">后端</a></div><div class="post_share"><div class="social-share" data-image="https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/C%2B%2B.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/%E6%94%AF%E4%BB%98%E5%AE%9D%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg" alt="支付宝"/><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/05/12/C++io/"><img class="prev_cover lazyload" data-src="https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/C%2B%2B.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">常用C++输入场景</div></div></a></div><div class="next-post pull_right"><a href="/2020/04/26/wechat4/"><img class="next_cover lazyload" data-src="https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/wechaticon.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">从零开发微信小程序（四）</div></div></a></div></nav></article></main><footer id="footer" style="background-image: url(https://nandodu-blog.oss-cn-shanghai.aliyuncs.com/u%3D570608382%2C3161007299%26fm%3D26%26gp%3D0.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 By NandoDu</div><div class="framework-info"><span>Driven </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script defer id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script id="ribbon_piao" mobile="true" src="/js/third-party/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/third-party/ClickShowText.js"></script><script src="/js/search/local-search.js"></script></body></html>